import sys
sys.path.insert(0, "/work/toltec/wilson/OOF/LMTOOF/python")

import yaml
import numpy as np
import tensorflow as tf
from pathlib import Path
from scipy.signal import correlate2d
from scipy.ndimage import shift

from TolTECBeamMap3 import TolTECBeamMap
from oof_ml.utils.data_generation_utils import generate_data_files


class MultiBandDataLoader:
    """
    Loads TolTEC data for multiple bands (e.g., a2000, a1400, a1100).
    Each band is handled similarly, but we look for the corresponding FITS files
    matching the band string.
    """

    def __init__(self, config_dir, crop_size=(32, 32), bands=None):
        """
        :param config_dir: Path or str to the directory containing config.yaml
        :param crop_size: (height, width) of the central crop
        :param bands: List of band strings, e.g. ["a2000", "a1400", "a1100"]
        """
        self.config_dir = Path(config_dir)
        self.crop_height, self.crop_width = crop_size
        self.bands = bands if bands else ["a2000", "a1400", "a1100"]

        # Store loaded images in a dict keyed by band
        # e.g. self.images[band] = (1, cropH, cropW, 3)
        self.images = {}
        # Also store the underlying "obsmaps" for each band if needed
        # e.g. self.fp[band] = dictionary of {obsnum -> {...}}
        self.fp = {}

        # Load config once
        self.config = self._load_config()

        # For each band, load data
        self._load_all_bands()

    def _load_config(self):
        """
        Reads the config.yaml file (which presumably has 'path' and 'obsnums').
        """
        config_file = self.config_dir / "config.yaml"
        with open(config_file, 'r') as f:
            config = yaml.safe_load(f)
        return config

    def _central_crop(self, image, crop_height, crop_width):
        """
        Extract a central crop of size crop_height x crop_width from the image.
        """
        height, width = image.shape[:2]
        start_y = (height - crop_height) // 2
        start_x = (width - crop_width) // 2
        return image[start_y:start_y + crop_height, start_x:start_x + crop_width]

    def _get_fits_data_for_band(self, band):
        """
        Loads TolTEC data for a given band (e.g., 'a2000'), returning a dict
        of the form:
          { obsnum: { 'path': str, 'file': str, 'tbm': TolTECBeamMap(...) }, ... }
        We assume the file pattern is 'toltec_*{band}*.fits'.
        """
        path = self.config['path']
        obsnums = self.config['obsnums']

        # Build dictionary of file paths for each obsnum
        fp = {}
        for obs in obsnums:
            # The directory containing the fits for this obs
            raw_dir = Path(path) / str(obs) / "raw"
            pattern = f"toltec_*{band}*.fits"
            found = list(raw_dir.glob(pattern))
            if not found:
                raise FileNotFoundError(
                    f"No fits found for obsnum={obs}, band={band} with pattern='{pattern}'."
                )
            fits_file = str(found[0])

            fp[obs] = {
                'path': str(raw_dir),
                'file': fits_file,
                'tbm': TolTECBeamMap(fits_file, obs, 0, str(raw_dir), 0, 0),
            }
        return fp

    def _make_test_images_for_band(self, fp):
        """
        For each observation in fp, extracts the 'signal' image,
        crops its central 32x32 pixels, and packs them into a numpy array.

        The output array will have shape (1, crop_height, crop_width, 3),
        where the last dimension indexes the 3 "sub-channels" for that band.
        """
        images = np.zeros((1, self.crop_height, self.crop_width, 3))
        i = 0
        for obsnum in fp:
            im = fp[obsnum]['tbm'].signal
            im_cropped = self._central_crop(im, self.crop_height, self.crop_width)
            images[0, :, :, i] = im_cropped
            i += 1

        # Renormalize amplitudes (per sub-channel)
        for i in range(3):
            chan_max = images[0, :, :, i].max()
            if chan_max != 0:
                images[0, :, :, i] /= chan_max

        return images

    def _load_all_bands(self):
        """
        For each band in self.bands, load the data and prepare the (1, H, W, 3) array.
        Store in self.fp[band] and self.images[band].
        """
        for band in self.bands:
            fp_band = self._get_fits_data_for_band(band)
            self.fp[band] = fp_band
            self.images[band] = self._make_test_images_for_band(fp_band)


class ModelEvaluator:
    def __init__(self, model_path):
        """
        :param model_path: Path or str to a saved Keras model.
        """
        self.model_path = Path(model_path)
        self.model = self._load_model()

        # We define a lookup for each band so we know what to pass as band_info.
        self.band_info_lookup = {
            "a2000": {"id": "2000", "wavelength": "0.002", "noise": "0.0"},
            "a1400": {"id": "1400", "wavelength": "0.0014", "noise": "0.0"},
            "a1100": {"id": "1100", "wavelength": "0.0011", "noise": "0.0"},
        }

    def _load_model(self):
        print(f"Loading model from {self.model_path}...")
        return tf.keras.models.load_model(str(self.model_path))

    def run_prediction(self, images):
        """
        Runs the model on the provided images (shape (N, H, W, 3)).
        Returns a predictions array of shape (N, #outputs).
        """
        print("Running predictions on input images...")
        return self.model.predict(images)

    def generate_images_from_prediction(self, prediction, band):
        """
        Given a 'prediction' vector of shape (10,), where the first 9 values
        correspond to Zernike terms (TILT_H, TILT_V, AST_V, AST_O, COMA_H, COMA_V,
        TRE_O, TRE_V, SPH) and the 10th is M2Z_OFFSET, this method returns
        a (H, W, 3) model image for the specified band.

        We use a unified utility (generate_data_files) so that all code
        for writing zernike.dat, subref.dat, and calling create_data_files
        is centralized.
        
        IMPORTANT: This returns the model images *without* any per-channel 
                   normalization, so we can measure amplitude directly
                   (e.g., for 'in_focus_gain').
        """
        if band not in self.band_info_lookup:
            raise ValueError(f"Unknown band '{band}'. Please check band_info_lookup keys.")
        band_info = self.band_info_lookup[band]

        # 1) Unpack the predicted parameters.
        zernike_values = prediction[:9]  # the 9 free Zernike terms
        m2z_offset = prediction[9]       # defocus offset

        # 2) Build the param_dict for the 9 Zernike terms in your template.
        param_dict = {
            "TILT_H": float(zernike_values[0]),
            "TILT_V": float(zernike_values[1]),
            "AST_V":  float(zernike_values[2]),
            "AST_O":  float(zernike_values[3]),
            "COMA_H": float(zernike_values[4]),
            "COMA_V": float(zernike_values[5]),
            "TRE_O":  float(zernike_values[6]),
            "TRE_V":  float(zernike_values[7]),
            "SPH":    float(zernike_values[8]),
            # FOCUS remains 0.0 by default in your template 
            # (only needed if you want to override it).
        }

        # 3) Call the unified utility to run the external simulation and return images.
        #    'generate_data_files' will produce a (32, 32, 3) array by default.
        model_imgs = generate_data_files(
            param_dict=param_dict,
            output_dir="temp_oof_sim",     # or your desired scratch directory
            jobname="model",
            channel_id=band_info["id"],
            wavelength=band_info["wavelength"],
            noise=band_info["noise"],
            m2z_offset=m2z_offset
        )

        # 4) Return the unnormalized images so that amplitude measurements are possible.
        return model_imgs


class ImageAligner:
    """
    Aligns data and model images channel-by-channel using cross-correlation,
    computes residuals and some standard metrics.
    """

    @staticmethod
    def _find_best_offset(data, model):
        corr = correlate2d(data, model, mode='full')
        y0, x0 = np.unravel_index(np.argmax(corr), corr.shape)
        offset_y = y0 - (model.shape[0] - 1)
        offset_x = x0 - (model.shape[1] - 1)
        return offset_y, offset_x

    def align_images_and_compute_residuals(self, data_images, model_images):
        """
        :param data_images: (H, W, 3) data
        :param model_images: (H, W, 3) model
        :return: aligned_model, residuals, offsets, metrics
        """
        aligned_model = np.zeros_like(model_images)
        residuals = np.zeros_like(model_images)
        offsets = {}
        metrics = {}

        for i in range(3):
            data_chan = data_images[:, :, i]
            model_chan = model_images[:, :, i]

            offset_y, offset_x = self._find_best_offset(data_chan, model_chan)
            offsets[f"channel_{i}"] = {"offset_y": int(offset_y), "offset_x": int(offset_x)}

            shifted = shift(model_chan, shift=(offset_y, offset_x), order=0, mode='constant', cval=0)
            aligned_model[:, :, i] = shifted

            diff = data_chan - shifted
            residuals[:, :, i] = diff

            mse_val = float(np.mean(diff**2))
            corr_coef = float(np.corrcoef(data_chan.ravel(), shifted.ravel())[0, 1])

            metrics[f"channel_{i}"] = {
                "mse": mse_val,
                "pearson_corr": corr_coef
            }

        return aligned_model, residuals, offsets, metrics


class OOFAnalysisPipeline:
    """
    Orchestrates loading data for multiple bands, running a single ML model, 
    generating band-specific model images, aligning them, and saving results.
    """

    def __init__(self, 
                 config_dir='fg131833',
                 model_path='../results_250330/zernike_predictor_best.keras',
                 output_dir='.',
                 crop_size=(32, 32),
                 bands=None):
        """
        :param config_dir: Directory with config.yaml
        :param model_path: Path to Keras model
        :param output_dir: Where to save results
        :param crop_size: (H, W) for central crop
        :param bands: list of band strings, e.g. ["a2000","a1400","a1100"]
        """
        self.config_dir = Path(config_dir)
        self.model_path = Path(model_path)
        self.output_dir = Path(output_dir)
        self.crop_size = crop_size
        self.bands = bands if bands else ["a2000", "a1400", "a1100"]

        self.data_loader = MultiBandDataLoader(
            self.config_dir, crop_size=self.crop_size, bands=self.bands
        )
        self.model_evaluator = ModelEvaluator(self.model_path)
        self.aligner = ImageAligner()

        # Will hold the final dictionary of band results
        self.band_results = {}
        # Will hold the final predicted Zernike parameters
        self.zernikes = None

    def run(self):
        """
        Overall pipeline flow:
         1) Load data for each band (already in data_loader)
         2) Run ML model once to get predicted Zernike parameters (using e.g. a2000)
         3) Generate model images for each band from that prediction
         4) Align data vs. model for each band
         5) Store results in a band-organized dictionary
         6) Save NPZ + manifest
        """
        # Step 1 is done automatically by the data loader.

        # Step 2: Obtain Zernikes from the a2000 data
        a2000_images = self.data_loader.images["a2000"]  # shape (1, H, W, 3)
        prediction_full = self.model_evaluator.run_prediction(a2000_images)
        self.zernikes = prediction_full[0]  # shape (10,) if that's your model definition

        # Step 3 & 4: For each band, generate unnormalized model images, measure gain,
        # then optionally normalize for alignment, align, and store results.
        for band in self.bands:
            # Data images for this band
            data_images = self.data_loader.images[band][0]  # shape (H, W, 3)

            # Generate unnormalized model images
            model_imgs_raw = self.model_evaluator.generate_images_from_prediction(self.zernikes, band)

            # Measure the in-focus amplitude (channel=1)
            in_focus_amplitude = float(model_imgs_raw[:, :, 1].max())

            # Now normalize each channel so alignment computations stay consistent:
            model_imgs_norm = np.zeros_like(model_imgs_raw)
            for chan_idx in range(3):
                cmax = model_imgs_raw[:, :, chan_idx].max()
                if cmax != 0:
                    model_imgs_norm[:, :, chan_idx] = model_imgs_raw[:, :, chan_idx] / cmax
                else:
                    model_imgs_norm[:, :, chan_idx] = model_imgs_raw[:, :, chan_idx]

            # Align using normalized images
            aligned_model, residuals, offsets, metrics = (
                self.aligner.align_images_and_compute_residuals(data_images, model_imgs_norm)
            )

            # Store results
            self.band_results[band] = {
                "data_images": data_images,        # already normalized per channel in the loader
                "model_images_raw": model_imgs_raw,  # unnormalized model
                "model_images_norm": model_imgs_norm, # normalized model
                "aligned_model": aligned_model,       # aligned normalized model
                "residuals": residuals,
                "offsets": offsets,
                "metrics": metrics,
                "in_focus_gain": in_focus_amplitude,  # raw amplitude
            }

        # Step 6: Save all results
        self._save_results()

    def _save_results(self):
        """
        Save band-organized results + Zernike parameters to NPZ, plus a YAML manifest.
        The manifest now includes:
          1) The contents of the config.yaml file,
          2) The name of the directory containing config.yaml,
          3) The zernike_names.
        """
        # Read the raw config.yaml contents.
        config_file = self.config_dir / "config.yaml"
        with open(config_file, 'r') as f:
            config_contents = f.read()

        # Get the name of the directory containing config.yaml.
        config_dir_name = self.config_dir.name

        # Define the zernike names.
        zernike_names = ["TILT_H", "TILT_V", "AST_V", "AST_O", "COMA_H", "COMA_V", "TRE_O", "TRE_V", "SPH", "M2Z_OFFSET"]

        # Create a manifest describing the overall run.
        manifest = {
            "description": (
                "Analysis performed for multiple bands (a2000, a1400, a1100). "
                "We used cross-correlation to align the model images to the data for each band. "
                "Metrics include MSE and Pearson correlation. The 'in_focus_gain' field in each band "
                "reflects the *unnormalized* amplitude of the in-focus model channel."
            ),
            "bands": self.bands,
            "zernikes": self.zernikes.tolist(),  # store as list for portability
            "config_contents": config_contents,
            "config_directory": config_dir_name,
            "zernike_names": zernike_names,
        }

        # Save the manifest as YAML.
        manifest_path = self.output_dir / "results_manifest.yaml"
        with open(manifest_path, 'w') as f:
            yaml.dump(manifest, f)
        print(f"Manifest saved to {manifest_path}")

        # Save the band_results dictionary and the zernikes in an NPZ.
        # Using allow_pickle=True to store the nested dictionary structure.
        npz_path = self.output_dir / "results.npz"
        np.savez(
            npz_path,
            band_results=self.band_results,
            zernikes=self.zernikes,
            allow_pickle=True
        )
        print(f"Results saved to {npz_path}")


if __name__ == "__main__":
    pipeline = OOFAnalysisPipeline(
        config_dir="fg131833",
        model_path="../results_250330/zernike_predictor_best.keras",
        output_dir=".",
        crop_size=(32, 32),
        bands=["a2000", "a1400", "a1100"]  # or whichever bands you want
    )
    pipeline.run()
    print("Multi-band analysis complete.")
